{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial TGAN\n",
    "\n",
    "## Time-series Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows how to use TGAN to generate synthetic time-series data. We are using Google Stock and Sine dataset as examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment Settings (Import necessary packages and functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish importing necessary packages and functions\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "#%% Functions\n",
    "# 1. Models\n",
    "from tgan import tgan\n",
    "\n",
    "# 2. Data Loading\n",
    "from data_loading import google_data_loading, sine_data_generation\n",
    "\n",
    "# 3. Metrics\n",
    "sys.path.append('metrics')\n",
    "from discriminative_score_metrics import discriminative_score_metrics\n",
    "from visualization_metrics import PCA_Analysis, tSNE_Analysis\n",
    "from predictive_score_metrics import predictive_score_metrics\n",
    "\n",
    "print('Finish importing necessary packages and functions')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set main parameters and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google dataset is ready.\n"
     ]
    }
   ],
   "source": [
    "#%% Main Parameters\n",
    "# Data\n",
    "data_set = ['google','sine']\n",
    "data_name = data_set[0]\n",
    "\n",
    "# Experiments iterations\n",
    "Iteration = 2\n",
    "Sub_Iteration = 3\n",
    "\n",
    "#%% Data Loading\n",
    "seq_length = 24\n",
    "\n",
    "if data_name == 'google':\n",
    "    dataX = google_data_loading(seq_length)\n",
    "elif data_name == 'sine':\n",
    "    No = 10000\n",
    "    F_No = 5\n",
    "    dataX = sine_data_generation(No, seq_length, F_No)\n",
    "\n",
    "print(data_name + ' dataset is ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set network parameters & Output initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters are {'hidden_dim': 24, 'num_layers': 3, 'iterations': 10000, 'batch_size': 128, 'module_name': 'lstm', 'z_dim': 6}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#%% Newtork Parameters\n",
    "parameters = dict()\n",
    "\n",
    "parameters['hidden_dim'] = len(dataX[0][0,:]) * 4\n",
    "parameters['num_layers'] = 3\n",
    "parameters['iterations'] = 10000\n",
    "parameters['batch_size'] = 128\n",
    "parameters['module_name'] = 'lstm'   # Other options: 'lstm' or 'lstmLN'\n",
    "parameters['z_dim'] = len(dataX[0][0,:]) \n",
    "\n",
    "print('Parameters are ' + str(parameters))\n",
    "\n",
    "#%% Experiments\n",
    "# Output Initialization\n",
    "Discriminative_Score = list()\n",
    "Predictive_Score = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run TGAN & Evaluate discriminative and predictive scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-25 18:32:58.664412: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-12-25 18:32:58.664427: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "ename": "InaccessibleTensorError",
     "evalue": "Operation init_3 has been marked as not fetchable. Typically this happens when it is defined in another function or code block. Use return values, explicit Python locals or TensorFlow collections to access it.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInaccessibleTensorError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Each Iteration\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Iteration):\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m     \n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Synthetic Data Generation\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     dataX_hat \u001b[38;5;241m=\u001b[39m \u001b[43mtgan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m   \n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinish Synthetic Data Generation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m#%% Performance Metrics\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# 1. Discriminative Score\u001b[39;00m\n",
      "File \u001b[0;32m~/personal/programs/Quantico/timegan/timegan/tgan.py:322\u001b[0m, in \u001b[0;36mtgan\u001b[0;34m(dataX, parameters)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;66;03m#%% Sessions    \u001b[39;00m\n\u001b[1;32m    321\u001b[0m sess \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mSession()\n\u001b[0;32m--> 322\u001b[0m sess\u001b[38;5;241m.\u001b[39mrun(tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mglobal_variables_initializer())\n\u001b[1;32m    324\u001b[0m \u001b[38;5;66;03m#%% Embedding Learning\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStart Embedding Network Training\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/my_new_env/lib/python3.10/site-packages/tensorflow/python/client/session.py:972\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    969\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 972\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m    975\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/my_new_env/lib/python3.10/site-packages/tensorflow/python/client/session.py:1200\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1197\u001b[0m       feed_map[compat\u001b[38;5;241m.\u001b[39mas_bytes(subfeed_t\u001b[38;5;241m.\u001b[39mname)] \u001b[38;5;241m=\u001b[39m (subfeed_t, subfeed_val)\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;66;03m# Create a fetch handler to take care of the structure of fetches.\u001b[39;00m\n\u001b[0;32m-> 1200\u001b[0m fetch_handler \u001b[38;5;241m=\u001b[39m \u001b[43m_FetchHandler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_handles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeed_handles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;66;03m# Run request and get response.\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;66;03m# We need to keep the returned movers alive for the following _do_run().\u001b[39;00m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;66;03m# These movers are no longer needed when _do_run() completes, and\u001b[39;00m\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;66;03m# are deleted when `movers` goes out of scope when this _run() ends.\u001b[39;00m\n\u001b[1;32m   1207\u001b[0m \u001b[38;5;66;03m# TODO(yuanbyu, keveman): Revisit whether we should just treat feeding\u001b[39;00m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;66;03m# of a handle from a different device as an error.\u001b[39;00m\n\u001b[1;32m   1209\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_with_movers(feed_dict_tensor, feed_map)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/my_new_env/lib/python3.10/site-packages/tensorflow/python/client/session.py:498\u001b[0m, in \u001b[0;36m_FetchHandler.__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fetch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetch_mapper\u001b[38;5;241m.\u001b[39munique_fetches():\n\u001b[1;32m    497\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fetch, ops\u001b[38;5;241m.\u001b[39mOperation):\n\u001b[0;32m--> 498\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assert_fetchable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_targets\u001b[38;5;241m.\u001b[39mappend(fetch)\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ops\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/my_new_env/lib/python3.10/site-packages/tensorflow/python/client/session.py:514\u001b[0m, in \u001b[0;36m_FetchHandler._assert_fetchable\u001b[0;34m(self, graph, op)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_assert_fetchable\u001b[39m(\u001b[38;5;28mself\u001b[39m, graph, op):\n\u001b[1;32m    513\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mis_fetchable(op):\n\u001b[0;32m--> 514\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInaccessibleTensorError(\n\u001b[1;32m    515\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOperation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mop\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has been marked as not fetchable. Typically \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    516\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthis happens when it is defined in another function or code block. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUse return values, explicit Python locals or TensorFlow collections \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    518\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto access it.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mInaccessibleTensorError\u001b[0m: Operation init_3 has been marked as not fetchable. Typically this happens when it is defined in another function or code block. Use return values, explicit Python locals or TensorFlow collections to access it."
     ]
    }
   ],
   "source": [
    "\n",
    "print('Start iterations') \n",
    "    \n",
    "# Each Iteration\n",
    "for it in range(Iteration):\n",
    "\n",
    "    \n",
    "    # Synthetic Data Generation\n",
    "    dataX_hat = tgan(dataX, parameters)   \n",
    "      \n",
    "    print('Finish Synthetic Data Generation')\n",
    "\n",
    "    #%% Performance Metrics\n",
    "    \n",
    "    # 1. Discriminative Score\n",
    "    Acc = list()\n",
    "    for tt in range(Sub_Iteration):\n",
    "        Temp_Disc = discriminative_score_metrics (dataX, dataX_hat)\n",
    "        Acc.append(Temp_Disc)\n",
    "    \n",
    "    Discriminative_Score.append(np.mean(Acc))\n",
    "    \n",
    "    # 2. Predictive Performance\n",
    "    MAE_All = list()\n",
    "    for tt in range(Sub_Iteration):\n",
    "        MAE_All.append(predictive_score_metrics (dataX, dataX_hat))\n",
    "        \n",
    "    Predictive_Score.append(np.mean(MAE_All))    \n",
    "    \n",
    "print('Finish TGAN iterations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization (PCA Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_Analysis (dataX, dataX_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization (t-SNE Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tSNE_Analysis (dataX, dataX_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print Discriminative and Predictive Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Results\n",
    "print('Discriminative Score - Mean: ' + str(np.round(np.mean(Discriminative_Score),4)) + ', Std: ' + str(np.round(np.std(Discriminative_Score),4)))\n",
    "print('Predictive Score - Mean: ' + str(np.round(np.mean(Predictive_Score),4)) + ', Std: ' + str(np.round(np.std(Predictive_Score),4)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
